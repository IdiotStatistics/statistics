\chapter{モデルにおける尤度比の性質}
モデル$M$において得られるデータ元に、母数を最尤推定する。新たに作られた最尤モデル上での尤度と元のモデル$M$での尤度の比がある分布に従うことがわかっている。
このことを利用して、モデルにおいてその尤度比以上の値の出現確立が計算可能である。
さらに、特定のモデル$M$において、尤度比がありふれた値であるかどうかを考えることにより、モデルがデータを予測できるのかを考える。

前の章で統計検定をモデル鳥によって説明した。あるモデル鳥が生んだ標本卵に関する統計量のばらつきの特徴と、研究者が持ってきたデータ卵を比較し、そのモデル鳥が産んだと判定していいのかを考える方法と説明した。
ここでも、どのモデルが生んだ標本卵に関わる統計的性質なのかを説明する。
%あるフルモデルにおける予想分布をまずは考察する。

%尤度比は統計量の一つであり、
%一方で、二つのモデルの間の類似度である検出力は定義できない\footnote{少なくとも本書ではやらない}。
%前章での$Z$値と同じように、尤度比がある値より大きい確率が$p$値である。


\section{概要}

モデル$M^{'}$により、実世界から無作意抽出して得た標本$D^{'}$を予測できるかを尤度比により検証する。
パラメータの個数が$k$個多いフルモデル$M$とし、モデル$M^{'}$の尤度比を次で計算する。
\begin{equation*}
    Dev(D,M',M)
\end{equation*}
$D\sim M^{'}$ならば、母数の個が$k$個多いモデル$M$との尤度比$Dev(D,M',M)$は、自由度$k$の$\chi^2$分布に従う。
$Dev$の定義は、式\ref{likelihood_equation}を参照せよ。

ここで、モデルとは無関係なデータ$D'$について、$D'$を$M^{'}$により説明しにくいなら、尤度比$Dev(D',M,M')$は比較的大きな値を取るはずである。
言い替えれば、モデル$M^{'}$の標本が取り得る尤度比と比較して、珍しくない尤度比であるならば、それは、$M^{'}$において予測できると考えることにする。
このことから、$Dev(D,M,M')$が比較的小さな値であれば($p$値は比較的大きくなっている)、モデル$M^{'}$によって予測可能かなぁと考えられる。

もちろん、標本を要約した統計量による検証なので、標本とモデルの詳細な検討ができていないので、そのモデルを採用可能かはわからない。

\subsection{尤度比の従う分布の数値計算}
例えば、正規モデル$M^{'}=M(170,5.8^2)$から標本$D$を生成する。その$\mu$に対する最尤モデル$M(\hat{\mu}\prime5.8^2)$とする。
この正規モデル$M^{'}$に対する尤度比は、次のようになる。
\begin{equation*}
    Dev(D,M(170,5.8),M(\hat{\mu})(D)) \sim \chi^2_1
\end{equation*}
データ由来の母数は最尤推定を行った$\mu$なので、その母数の個数は$1$であり、ゆえに尤度比は自由度$1$の$\chi^2$分布に従う。

\subsubsection{実データへの適用}
モデルと同じ確率密度関数からサンプリングを行い、尤度比検定を行なってみる。

数値実験を行なってみる。具体的に、正規分布$N(170,5.8^2)$からサンプリングした標本1000個を集める。
標本から平均値を求め、これを最尤推定量とする(xbar)。
この最尤モデル$M(\mu;\sigma^2=5.8^2) $における標本の尤度を計算する(loglike2)。
同様に、モデル$M(170;\sigma^2=5.8^2)$における標本の尤度を計算する(loglike)。
以上から尤度比を計算し、それが$\chi^2_1$分布と一致することを確かめる。
以下がコードである。

\begin{lstlisting}
norm_ = norm(170,5.8)
data_ = norm.rvs(170,5.8,size=(1000,10))
xbar = np.average(data_,axis=1)
loglike_ = np.prod(norm_.pdf(data_),axis=1)
#loglike2_ = np.prod(norm(xbar,5.8).pdf(data_),axis=0)
#print(np.prod(norm(xbar,5.8).pdf(data_),axis=1),xbar)

loglike2_ = []
for item in data_:
    #print(item.shape)
    a = norm(np.average(item),5.8).pdf(item)
    loglike2_.append(np.prod(a))

y = -2*np.log(loglike_/loglike2_)
x = sorted(y)
y_ = np.arange(len(y))/len(x)
plt.plot(x,y_)
plt.plot(x,chi2.cdf(x,df=1))
plt.show()

\end{lstlisting}

$N(170,5.8^2)$と$N(175,5.8^2)$と言う2種類の密度関数からサンプリングを行いそれぞれ結果を図\ref{fig:loglikelihood_test_simulation_norm}(a)および(b)に示す。
図\ref{fig:loglikelihood_test_simulation_norm}(a)は、モデルとデータの分布が一致していることから、累積分布が$\chi^2_1$の累積分布にかなり近いことがわかる。
図\ref{fig:loglikelihood_test_simulation_norm}(b)は、モデルとデータが一致していない状況での結果を示している。尤度比の多くが右に移動しており、標本の多くが$\chi^2_1$において珍しいと判定されやすくなっている。


\begin{figure}
    \begin{center}
        \includegraphics[width=15cm]{./image/04_/loglikeli_norm_test.pdf}
        \caption{対数尤度比の累積頻度。モデルは正規モデル$M(170;\sigma^2=5.8^2)$。(a)標本を$N(170,5.8^2)$からサンプリングした結果。(b)標本を$N(175,5.8^2)$からサンプリングした標本。}
        \label{fig:loglikelihood_test_simulation_norm}

      \end{center}
    \end{figure}

\subsection{正規モデルにおける尤度比検定の計算}

$\sigma^2_0$を設定した正規モデル$M(\mu_0;\sigma^2_0)$について考察する。
この正規モデルからサンプリングを行なった標本$X$とする。
標本から得た最尤正規モデルを$M(\bar{x};\sigma^2_0)$とする。ここで、$\bar{x}$は標本$X$の標本平均。
それぞれのモデル内での標本$X$の尤度を$L(\mu_0,X),L(\bar{x},X)$とする。
具体的な数式は、
\begin{eqnarray*}
    L(\mu_0,X)=\frac{1}{\sqrt{2\pi\sigma_0^2}}\exp(-\frac{\sum(x_i-\mu_0)^2}{2\sigma^2})\\
    L(\bar{x},X)=\frac{1}{\sqrt{2\pi\sigma_0^2}}\exp(-\frac{\sum(x_i-\bar{x})^2}{2\sigma^2})
\end{eqnarray*}
これらから$-2\log \lambda(X)$を計算する。
\begin{eqnarray*}
 -2\log\lambda(X) &=& -2\log\frac{L(\mu_0,X)}{L(\bar{x},X)} \\
 &=&\frac{ \sum (x_i-\mu_0)^2}{\sigma^2_0}-\frac{\sum (x_i-\bar{x})^2}{\sigma_0^2} \\
 &=& \frac{ \sum(x_i^2-x_i^2) -2n\mu_0\bar{x} +n\mu_0^2-n\bar{x}^2 +2n\bar{x}^2} {\sigma_0^2}\\
% &=& -2(-\frac{n}{2\sigma^2_0}(\bar{x}-\mu_0)^2) \\
&=& \frac{n}{\sigma_0^2}(\mu_0^2 -2\mu_0\bar{x} +\bar{x}^2)  \\
 &=& \frac{n}{\sigma^2_0}(\bar{x}-\mu_0)^2 
\end{eqnarray*}
これが、$\chi^2_1$に従う。



\subsection{データとモデルの乖離を検証する}
モデル上において、その標本を元にした最尤モデルにおける尤度比が$\chi^2_1$に従うことを示した。このことを元に、データをモデルによって予測可能かを調べる。手順は、
\begin{enumerate}
    \item 標本を$x$とする。
    \item モデル$M$における最尤推定量を計算する。
    \item モデル$M$および最尤モデル$M_{MLE}$における標本$x$に対する尤度を計算する
    \item 尤度比および$-2\log\lambda(x)$を計算し、$\chi^2_1$において珍しい値なのかを検証する。
\end{enumerate}
実際に、正規モデルにおいてこの手順をなぞってみる。
$M(\mu;\sigma^2)$における最尤モデルは、$M(\bar{x};\sigma^2)$である。
それぞれのモデルにおける尤度を計算し、$-2\log\lambda(x)$を計算すればよい。


%\section{データと当てはめモデル$\hat{M}$の比較}

\section{データと当てはめモデル$\hat{M}$の比較}
データを当てはめたモデル$\hat{M}$とデータの比較。
次を計算する。
\begin{equation*}
    Dev(D,\hat{M},\hat{\hat{M}})
\end{equation*}
ここで、標本$D'$の最尤推定モデルを$\hat{M}$とし、$D$を$\hat{M}$の標本とし、$\hat{\hat{M}}$は$\hat{M}$の$p$個の母数に対して$D$に対して最尤推定を行なったモデルである。
$Dev(D,\hat{M},\hat{\hat{M}}) $の分布$\chi^2_p$の中で、モデル由来ではない標本$D'$に対する尤度比$Dev(D',\hat{M},\hat{\hat{M}}) $が珍しい値を取っていたなら、
$\hat{M}$から考えられる尤度比の変動の中では、比較的大きな変動が起きていることが示唆される。
このことから、$\hat{M}$で標本を予想しない方が良いのではないだろうかと判断する。

\subsection{注意点}
いくつか注意するべきことがある。
\begin{enumerate}
 \item $\hat{M}$が$D'$を予測しているかはこれだけでは不明(小節\ref{likelihood_model_unpredictable})。
 \item $\hat{\hat{M}}$の方が良いとは言えてない。$\hat{M}$に対する絶対評価\footnote{当てはまりの良さは、尤度の大小関係を見れば良い。フルモデルの方が大概の場合当てはまりが良くなる。}。
 \item 「尤度の大小関係が有意であることを確かめるのが尤度比検定である。」などといわれることもあるが、本書とは異る方針の統計利用である。本書では、$p$が十分小ければ、$\hat{M}$による予測はやめておいたほうがよいという証拠の１つとする。
\end{enumerate}

%有意かどうかとはどういう意味かがわからない。$\hat{M}$の尤度比の変動では予測できないという意味であれば理解できる。さまざまな前提で検定が使われているので、解釈が一致しない。}。

\if 0
この性質を利用して、母数の数の異なるモデルに対して、最尤推定をそれぞれ行い、モデルを構成する。
ある統計モデル$M_1$とし、$M_1$の中でいくつかの母数を固定したモデル$M_2$とする。
$M_1$からサンプリングした標本とその最尤モデル$M_{1'}$は尤度の比が$\chi^2$に従う。
同様に、その標本に対する最尤モデル$M_{2'}$とすれば、$M_1$と$M_{2'}$の尤度比も$\chi^2$分布に従う。

ここで、母集団から無作為抽出した標本$D$とする。
$D$の最尤モデルを$M_{1''}$、$M_{2''}$とする。
これらモデル上での尤度の比を計算し、$\chi^2$においてどの程度の珍しさなのかを調べる。


そのモデルでのならば、どの程度の珍しさなのかを計算する。
尤度比が大きくなれば、$\chi^2$において珍しい値になり、$p$値が小さくなる。
言い換えれば、あるモデルで予想される尤度の比と比べて、データから導かれた尤度比が大きな変動かが計算できる。
\fi

\begin{SMbox}{尤度比検定で$p<0.05$だったので$M_1$より$M_2$がより適合的だ}
 尤度比検定で$p<0.05$だったので$M_1$より$M_2$がより適合的だという判断はしないほうが良い。
 尤度比検定において$p$値が小さいということは、
 $M_1$における尤度比の予測値の中で、比較的大きな尤度の変化が実験データでは生じていることを示したことになる。
 これは、$M_1$の中での変動と比較しているだけであり、相対的に$M_2$の方がより適合的であることを示唆していない。
 検定では、相対的なモデルのデータへの適合具合を示すことができない。

 より適合的であることを示す量の一つとしては、尤度が挙げられる。
 複数のモデルにおいて、対数尤度が小さいモデルがデータに対して適合しているという判断ができる。
\end{SMbox}



\if 0
\paragraph{尤度比}
データを指数分布から生成し、モデルを正規モデル$M$とする。
二つの母数についての最尤モデルと、平均
このとき、何度もデータを指数分布から生成し、尤度比を計算したとき、その尤度比は$\chi^2$に従うか？
%無作為抽出して得た標本に対して、あるモデルのその標本に対する最尤モデルを$M(\theta_1,\theta_2,\theta_3)$とする。
\fi

\subsection{まぜると危険}
尤度比検定を行えば、フルモデル\footnote{尤度比の分母にくるモデル}が採用できるという説明がされることがある。
これは以下の二つを混合している。
\begin{enumerate}
 \item 特定モデルに対する標本の乖離具合い
 \item モデル間のデータへの当てはまり具合に関する指標
\end{enumerate}

まず、統計的仮説検定では、特定モデルの標本の統計要約量以上の値がそのモデルで出現する確率が計算できる。
この道具を本書では、特定モデルとデータの乖離具合の指標の１つとして導入した。
尤度比検定についても、特定モデルに関するデータの乖離具合の指標である。
故に本書では、尤度比検定については、他のモデルの良さについては計れていないという立場をとる。

次に、モデル間のデータへの当てはまり具合について、式\ref{loglikelihood_equation_log_minus_log}$(Dev)$を観察する。
この式は、フルモデルの尤度と子モデルの差分を示している。$Dev$が$0$よりも小ければ、フルモデルの方が当てはまりが良く、$0$より大きければ、子モデルの方が当てはまりがよいことを示す。基本的には、母数の個数が多いフルモデルの方が当てはまりが良いので、対数尤度が大きくなる。このことから、$Dev$を計算するまでもなく、フルモデルの方があてはまりとしては良い。

これら二つのことをまぜあわせ、結論として、フルモデルが良いという主張がなされていることがある。
これら二つの評価とそして、得られた結果は別々に主張するべきことである\footnote{フルモデルの方がいいことはわかるが、フルモデルが実際に使えるかという意味では検証されていないことは常に注意。}\footnote{生物統計学では、混ぜて議論を行っている。いまさら混ぜるなとしてもあまり意味がないだろう。}。


\begin{SMbox}{滅多に観察されない逸脱度}
\begin{quote}
 有意確率が小さければ(通常は$5\%$以下)\footnote{有意確率はおそらく$p$値のこと}、2つのモデルの「逸脱度の差」は滅多に観察されないほど大きな値であると判断する。
\end{quote}
    これは本書とは異なる方針の科学における指針である。 本書では、ある統計モデルが予測した統計量と比較して大きな統計量が得られたからといって、現実的に滅多に観察されないとは解釈しない\footnote{
        この話は後でもう一度考えて見た方がいい気がする。
        できないはずであるが、できるとする論文が多い。なぜなんだろうTODO。
    }。
 本書が扱いたい科学において、 特殊なモデルで尤度比を使えば、現実での起こりやすさが検証できるということはない。
 %https://www.jstage.jst.go.jp/article/weed/55/4/55_4_275/_pdf
 %特集 統計解析（再？）入門 R を用いた一般化線形モデル（仮説検定編）: 割合データを例

 \begin{quote} 2つのモデルの「逸脱度の差」が大きいことから、すなわち、要因を覗くことでモデルの当てはまりが十分に悪くなることから、その要因は有意な要因であると判断する。
 \end{quote}
    これも本書とは異なる分野を研究しているのだと思われる。 尤度比の差の統計量を実データの尤度比の差と比べてわかるのは、フルモデルで予測または当てはめしない方が良さそうということである。
    より当てはまりのモデルかどうかは尤度比を比べればよい。
\end{SMbox}




\section{複雑なモデルでの尤度比検定}
次のモデル$M(\beta_1,\beta_2)$を考える。
\begin{enumerate}
    \item $x_i$は定数。
    \item $y_i$は以下に示す分布$p(y_i;\lambda_i)$に従う。
    \item $\lambda_i = \exp(\beta_1+\beta_2 x_i)$
    \item $y_i \sim p(y_i;\lambda_i) = \frac{\lambda_i^{y_i}\exp(-\lambda_i)}{y_i!}$
\end{enumerate}
無作為抽出した標本$x$における２つの最尤モデルを考える。
最初のモデルは、$\beta_2=0$とした上で、$\beta_2$に関する最尤推定を行なったモデル$M_1=M(\hat{\beta_1},\beta_2=0)$である。
このモデルでは、$x_i$に応じて、$\lambda_i$が変化しないので、$\lambda$が常に一定のモデルになる。言い換えれば、$y$が母数$\lambda=\exp(\beta_1)$のポアソン分布となるモデルである。
次のモデルは、$\beta_1,\beta_2$の両方について最尤推定を行なったモデル$M_2=M(\hat{\hat{\beta_1}},\hat{\hat{\beta_2}})$である。
このモデルにおいて、$(x_i,y_i)$はペアになっており、$x_i$に応じて$y_i$が揺らぎを持って決まる。

ここで、$M_1$における尤度比が$\chi_1^2$に従うことを確かめる。手順は以下の通りである。
\begin{enumerate}
    \item $M_1$においてサンプリングを行い、$(x_i,y_i)$からなる標本$X$を得る。$x_i$は、既存の標本$x$のものを使う。%$(x_i,y_i)$に関してバラバラになった標本が得られる。
    \item $M_1$における標本$X$の尤度$L_1$を計算する。
    \item $M_2$において、標本$X$を用いて、最尤モデルを構築し、そのモデルで尤度$L_2$を計算する。
    \item $-2\log\frac{L_1}{L_2}$を計算する。以上の手順を繰り返す。
\end{enumerate}
以上を行うと、尤度比$-2\log\frac{L_1}{L_2}$が$\chi^2_1$に従うことがわかる。図\ref{fig:loglikelihood_test_simulation_poisson}a,bに結果を載せている。

\subsubsection{数値計算}
コードを書いておく。
標本を$1000$個生成し、その尤度比を集め、$chi^2$の累積分布関数と比較した。
\begin{lstlisting}
df  = pd.read_csv("https://raw.githubusercontent.com/tushuhei/statisticalDataModeling/master/data3a.csv")

def get_dd(d):
    d['y_rnd'] = np.random.poisson(np.mean(d.y),len(d.y))
    model1 = smf.glm(formula='y_rnd~1',data=d,
    family=sm.families.Poisson())
    model2 = smf.glm(formula = 'y_rnd~x',data=d,family=sm.families.Poisson())
    #print(fit1.summary())
    fit1 = model1.fit()
    fit2 = model2.fit()
    return fit1.deviance - fit2.deviance

l = []
for i in range(1000):
    l.append(get_dd(df))


x = sorted(l)
y = np.arange(len(l))/len(l)
plt.plot(x,y)
plt.plot(x, chi2.cdf(x,df = 1))
plt.show()
\end{lstlisting}


\begin{figure}
    \begin{center}
        \includegraphics[width=15cm]{./image/04_/loglikeli_poisson_model_test.pdf}
        \caption{$M_1$における対数尤度比の累積頻度。(a)ヒストグラム(b)累積分布}
        \label{fig:loglikelihood_test_simulation_poisson}
    \end{center}
\end{figure}

\subsection{データとの比較}
データと、最尤モデル$M_1$との比較は同様に、
\begin{enumerate}
 \item 無作意抽出した標本を$x$とする(モデルから得た標本ではない。)
 \item 尤度$L_1$を$M_1$上で計算する。
 \item 標本$x$の尤度$L_2$を$M_2$上で計算する。
 \item $-2\log\frac{L_2}{L_1}$を計算する。
\end{enumerate}
最尤モデル$M_1$においてデータ$x$が予測できないなら、$-2\log\frac{L_2}{L_1}$が大きな値を取る。



\begin{comment}
最尤モデル$M_2$からサンプリングされた標本の尤度と、その標本から最尤推定量を計算し、構築した最尤モデル$M_1$において標本の尤度を計算したものとを比較すると、
$\chi^2_1$に従う。
なぜならば、ここにおける最尤モデル$M_2$のパラメータ$\beta_2$はほとんど0と変わりなく、小さな値をとるので、$M_1$と違いが少ない。
標本が$M_1$からサンプリングされていないなら、モデル$2$での最尤推定の結果、
$\beta_2$も$0$から離れてしまい、尤度比も大きくなるはずである。
$M_1$で標本$x$を予測しない方がよくないことを示す証拠の一つになる。
ただし、$M_2$が良い予測モデルであるのかは不明である。

$M_1$からサンプリングした標本で、$M_1$および$M_2$を推定したモデルの尤度比は$\chi^2_1$に従う。
実際の標本を元に、$M_1,M_2$を推定し、そのモデルの尤度比は、$M_1$による予測ができるならば、$\chi^2_1$程度だと考えられる。
実際にこの例では、尤度比が大きくなり、$\chi^2_1$においては珍しい値になったので、
$M_1$により予測しない方が良さそうと言う根拠の一つになりうる。
$M_2$の$\hat\hat\beta_2$のパラメータがどうなっているかなども気にした方が良さそう。 
\end{comment}


\begin{SMbox}{帰無仮説の取り方}
    \if 0
    \begin{theorem}
        $M_a$を$M_b$のネストされたモデルとする($M_b$の方が$M_a$よりもパラメータが多い)。このとき、$M_a$からサンプリングした標本$X$について、
        \begin{equation*}
            -2\log\frac{M_aにおけるXの尤度}{M_bにおけるXの最尤推定量}
        \end{equation*}
        は、ある自由度を持つカイ二乗分布に従う。
    \end{theorem}
\fi

    通常の尤度比検定は、次の通りである。
    \begin{theo}
        帰無仮説:$M_a=M(\alpha)$\\
        対立仮説:$M_b=M(\alpha,\beta\neq 0)$\\
        とする。このとき次が自由度1のカイ二乗分布に従う。
        \begin{equation*}
            -2\log\frac{帰無仮説における尤度}{M_aにおけるサンプルXを元にした最尤M(\alpha,\beta)での尤度}
        \end{equation*}
    \end{theo}

    「データ解析のための統計モデリング入門」では定理として示されてはいないが、恣意的にまとめてみると次のことが成立していると考えられている。
    \begin{theo}
        帰無仮説:$M_a=M(\alpha)$\\
        対立仮説:$M_b=M(\alpha,\beta\neq 0)$\\
        とする。このとき、次が自由度1のカイ二乗分布に従う。
        \begin{equation*}
            -2\log\frac{帰無仮説における尤度}{M(\alpha,\beta\neq 0)の最尤モデルにおける尤度}
        \end{equation*}
    \end{theo}
    尤度比が、数理統計学で紹介されるものとは異なっている。
 具体的には、分母における最尤推定される母数に関して制限がない物が通常の定理である。
 これが成立するのかは私にはわからないので、本書では採用していない。

    また、本書と異なる点は、対立仮説を採択している点である。
    \begin{quote}
        So we can state that 対立仮説 can be accepted.\footnote{\url{https://kuboweb.github.io/-kubo/stat/2019/Ees/d/kubostat2019d.pdf}}
    \end{quote}
 本書においては、尤度比検定ではモデルとの乖離を調べれるという方針なので、モデルとデータを比較していないのに、あるモデルを採択することはありえない\footnote{尤度比の性質は帰無仮説にがだめっぽいということを示している。どちらかのモデルの二者択一できるような物ではないとする。}。生物統計では、モデルとデータの乖離を十分検証しなくても、そのモデルを採用するということがあるという点は留意するべきであろう\footnote{ネストされたモデルとデータの乖離具合を調査したのか？という疑問が残ることが多々ある。}。
\end{SMbox}



\section{One-way ANOVA}
統計モデル$M_N= M (\mu,\sigma^2)$に対し、これを拡張したモデルを考える。
そのモデルは次の仮定をもつ。
\begin{enumerate}
    \item $\mu_i (i=1,2,\cdots,n)$
    \item $x_{ik} \sim N(\mu_i,\sigma^2)$
\end{enumerate}
ここで、$m=\sum_{i=1}^n n_i$と定義する。
これを統計モデル$M_A=M(\mu_1,\mu_2,\cdots,\mu_n)$とする。
フルモデルと子モデルそれぞれについて、最尤モデルを検討する。

\subsection{子モデルの最尤推定}
%$M_A$の子モデルを$M_N=M(\mu;\sigma^2)$とする。
%平均母数の個数を１つに絞ったモデルである。
%明らかに$M_N$は$M_A$のネストされたモデルである。
$M_N$から得られたサンプル$x$についてその最尤推定量は次のようになる。
%これは、正規モデルの最尤推定量なので
\begin{equation*}
    \bar{\mu}_{\rm{ML}} = \frac{1}{\sum_{i=1}^n n_i} \sum_{i=1}^n\sum_{k=0}^{n_i} x_{ik}, \\
    \bar{\sigma}_{\rm{ML}}^2 =  \frac{1}{\sum_{i=1}^n n_i} \sum_{i=1}^n \sum_{k=1}^{n_i}(x_{ik} -\bar{\mu}_{ML})^2
\end{equation*}
こモデルの尤度は、式\ref{anova_model_likelihood}を参考に考えると次のようになる。
\begin{eqnarray*}
 L_N&=& \prod_{i=1}^n \prod_{j=1}^{n_i}\frac{1}{\sqrt{2\pi \bar{\sigma}^2_{\rm{ML}}}}\exp\left(  -\frac{(x_{ij}-\bar{\mu}_{\rm{ML}}^2)}{2 \bar{\sigma}^2_{\rm{ML}}}\right) \\
&=&  (2\pi \bar{\sigma}^2_{\rm{ML}})^{-\frac{m}{2} }\exp\left(  -m/2\right) 
\end{eqnarray*}

\subsection{フルモデル}
%この統計モデルの$\mu_1=\mu_2=\cdots=\mu_n$としたときの最尤推定量を計算する。
$M_A$からサンプリングされた標本$x = (x_{ik}) (k=1,\cdots,n_i)$とすると、このモデルの尤度は次のようになる。
\begin{equation*}
    L(\mu;x) = \prod_{\substack{i=1,2,\cdots,n \\ k=1,\cdots,n_i}}\frac{1}{\sqrt{2\pi\sigma^2}}\exp(-\frac{(x_{ik}-\mu_i)^2}{2\sigma^2})
\end{equation*}
最尤推定量は次のようになる。
\begin{equation*}
 \bar{\mu_i} = \frac{1}{n_i}\sum_{j=1}^{n_i} x_{ij} = \bar{x_i},\\
 \bar{\sigma}^2 = \frac{1}{m} \sum_{i=1}^n \sum_{j=1}^{n_i} (x_{ij}-\bar{x_i})^2
\end{equation*}
尤度についても計算しておく。
\begin{eqnarray*}\label{anova_model_likelihood}
 L_A &=& \prod_{i=1}^n \prod_{j=1}^{n_i}\frac{1}{\sqrt{2\pi \bar{\sigma}^2}}\exp\left(  -\frac{(x_{ij}-\bar{\mu_i})^2}{2 \bar{\sigma}^2}\right) \\
 &=&  (2\pi \bar{\sigma}^2)^{-\frac{m}{2}}\exp\left(  -\frac{\sum_{i=1}^n \sum_{j=1}^{n_i} (x_{ij}-\bar{\mu_i})^2}{2 \bar{\sigma}^2}\right) \\
 &=&  (2\pi \bar{\sigma}^2)^{-\frac{m}{2}}\exp\left(  -\frac{ m \bar{\sigma}^2}{ 2\bar{\sigma}^2}\right) \\
 &=&  (2\pi \bar{\sigma}^2)^{-\frac{m}{2} }\exp\left(  -m/2\right) 
\end{eqnarray*}

\subsection{尤度比}
以上をもとに尤度比を計算する。
\begin{eqnarray*}
 \lambda =\frac{L_N}{L_A} &=& \frac{(2\pi \bar{\sigma}^2)^{-\frac{m}{2} }\exp\left(  -m/2\right) }{  (2\pi \bar{\sigma}^2_{\rm{ML}})^{-\frac{m}{2} }\exp\left(  -m/2\right)  }\\
 &=& \left( \frac{ \bar{\sigma}^2}{ \bar{\sigma}^2_{\rm{ML}} }\right)^{-\frac{m}{2}}\\
 &=& \left( \frac{ \bar{\sigma}^2}{ \bar{\sigma}^2_{\rm{ML}} }\right)^{-\frac{m}{2}} \\
&=& \left( \frac{ \sum_{i=1}^n \sum_{j=1}^{n_i} (x_{ij}-\bar{x_i})^2 }{ \sum_{i=1}^n \sum_{k=1}^{n_i}(x_{ik} -\bar{\mu}_{ML})^2 } \right)^{-\frac{m}{2}}
\end{eqnarray*}


%\right)^{\frac{-m}{2}}

\begin{comment}
\begin{equation*}
    -2\log \lambda(x) = \frac{L(\mu;\bar{\sigma}^2)}{L(\mu_1,\mu_2,\cdots,\mu_n,\bar{\sigma}^2_{ML})}
\end{equation*}

\end{comment}

%$M_N$において、このモデルの上位の$M(\mu_1,\mu_2,\cdots,\mu_n)$の最尤推定モデルと、$M_N$の尤度比がカイ二乗分布に従う。
$M_N$の標本$x$について、$-2\log \lambda(x)$が$\chi^2$分布に従う。
自由度は、$M_N$が$2$であり、$M_A$が、$n+1$なので、$\chi^2$の自由度は$n+1-2=n-1$である。

以上のことから、1つの平均値を設定したモデルとデータが乖離していることを調べることがで
きる。
モデル$M_N$における統計的性質であることに注意。


\begin{comment}
 
$-2\log\lambda$を計算すると、
\begin{equation*}
    F = \frac{\sum_i^k \frac{n_i (\bar{x}_i-\bar{x})^2}{k-1}}{ \sum_{i=0}^k\sum_{j=0}^{n_i}\frac{ (x_{ij}-\bar{x}_i)^2 }{n-k}}
\end{equation*}
である。
%$データ由来の母数の個数から1を引いた数が自由度になる。
つまり、
\begin{equation*}
 -2\log\lambda(x) = F\sim \chi^2_{n-1}
\end{equation*}
である。

\end{comment}

\begin{SMbox}{少なくとも一つは母数が違う}
    1-way ANOVAを使い、$p<\alpha$を得たならば、少なくとも一つは母数が違う郡が入っている。言い換えれば、帰無仮説が棄却され、対立仮説を採択している。    
    有意差検定では、対立仮説を採択することはないと説明している教科書でも、ANOVAでは対立仮説を採択していることがある\footnote{ハイブリッド検定が使われているので、その方針を採用しているだけである。}。
    
    本書では、$M_N$モデルとデータが乖離しているかもしれない程度しかわからないということにする。
    異なる母数で推測した方が良いという結論を得るには、検定以外の方法で、データを解析することが必要である。
\end{SMbox}

\subsection{数値計算}
統計的性質が現れることを数値計算により確かめてみる。
\begin{lstlisting}
mu = 170
sigma=5.8
n=10
sampleN = 200

norm_ = norm(mu,sigma)
l=[]
for i in range(10000):
    sample = norm_.rvs(size=(n,sampleN))

    ave_ = np.average(sample)
    sigma_ = np.std(sample) 
    #sigma_,ave_
    ave_s = np.average(sample,axis=1)
    sigma_s = np.std(sample,axis=1)
    ave_s.shape,sigma_s.shape

    lam = np.sum( (sample - ave_)**2)/np.sum( (sample.T - ave_s)**2)
    l.append((sampleN*n)*np.log(lam))

x = np.sort(l)
y = np.arange(len(l))/len(l)
plt.plot(x,y)
plt.plot(x ,chi2.cdf(x,df = n-1))
plt.show()
\end{lstlisting}
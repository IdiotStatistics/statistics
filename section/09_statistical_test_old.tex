\chapter{仮説検定}
仮説検定とは、仮説を採用するかを決定する方法である。数多くの研究で、科学的な検証がなされたことを示すために、仮説検定が利用されている。
その手順は、科学において合理的とは言いえない\footnote{数学的には正しいが、科学においては使えない方法である}。

%Fisherが有意検定を提案した後に、Neyman-Pearsonが仮説検定を提案し、その後、それらを組み合わせた仮説検定が利用されることになった。

科学的仮説検定では、データがある法則により推測可能であるかを示すため、モデルを構築した。
仮説検定では、モデルは出てこない。モデルの母数に関する仮説のみを帰無仮説と定義し、帰無仮説で指定した母数ではないを対立仮説と定義する。帰無仮説の元、標本の統計量以上の値が得られる確率を計算する。
$p$値が$0.05$よりも小さいならば、対立仮説を採択し、$p>\alpha$ならば帰無仮説を採択する\footnote{そんなことを仮説検定だけで行うのは不可能である。}
\footnote{モデルを考えないのは気持ち悪いので、帰無仮説$\mu=\mu_0$を帰無仮説を含む統計モデル$M(\mu_0)$(以下、帰無仮説モデル)と読み替えても良い}。

仮説検定の枠組みでは、モデルの仮定は前提でなければならないと考えられていることが多い\footnote{仮説検定を使う研究者にとって、モデルは頭の中に入っていないので、モデルの仮定ではなく、仮説検定をするための前提のことである}。
例えば、、データは独立同一の分布関数から得られている\footnote{これを確かめる方法はない。}。また、正規分布を仮定しているのであれば、データの分散と帰無仮説の分散が等しいなどである。
そのため、仮説検定を行う前に、いくつかの仮説検定を行い、これらの前提を確かめる。正規分布の仮定は、$Shapiro$検定を使う。その後、正規分布であれば、等分散検定などを行う。
これらの前段階の検定でも、$p$値が設定した$\alpha$よりも小さければ、対立仮説を採択し、$p>\alpha$であれば、帰無仮説を採用する\footnote{検定により対立仮説や帰無仮説を採択することはできないが、できるという立場をとる。なぜ？と疑問に感じるだろうが、決定手法なので、手順を順守しなければならない。}。
これは、帰無仮説は採択しないというFisherらの見解を採用していると言いつつ、実質的には、Neyman-Pearsonらの方法をとっているからである。
特に、最終的な仮説検定を行う前段階の仮説検定が行われており、その中では、帰無仮説または対立仮説のどちらか一方が必ず採択されている\footnote{検定では何もわからないはずのことを、わかるということにして運用されている。もしも、仮説検定の手順は分野によって手順が少しずつ異なるので、指導教員に手順を聞くことを勧める。手っ取り早く卒業したいのなら、魔術を信仰した方が良い。やれと言われたことをやらなければ論文は通らない。}
\footnote{科学的仮説検定と仮説検定とを互換可能な形にしてまとめたかったが、それは不可能である。仮説検定は仮説が検証できると盲信し、検証する方法である。これは、モデルとデータの乖離を検討するという考えと整合的に捉えることができない。}
\footnote{決定できるという考えを捨てていくべきである}
\footnote{仮説検定が廃止されたとしても、過去の研究においては仮説検定が使われており、それらから仮説を引き出さなければならない。この理由から仮説検定を理解しなければならない}。


\begin{SMbox}{有意性検定・仮説検定}
    Fisherは、帰無仮説を設定し、モデルとデータの乖離を調べる枠組みを構築した。これを、有意性検定ということがある。これに対して、Newman-Pearsonらは、帰無仮説に加えて、対立仮説を設定し、帰無仮説とデータが乖離していた場合、対立仮説を採択すると言う立場をとった。これを、仮説検定と呼ぶことがある。現代の科学の多くは、FisherとNewman-Pearsonの両方を組み合わせ、帰無仮説・対立仮説を設定し、帰無仮説とデータの乖離を調べ、棄却されたとしても、対立仮説を含むモデルを採択する。
        %有意性検定を統計学\cite{upton2010統計学辞典,2009数理統計ハンドブック}や数学\cite{日本数学会2007岩波数学辞典}の辞書で調べたが、該当する言葉は見つからなかった。一方で、仮説検定は統計学\cite{upton2010統計学辞典,2009数理統計ハンドブック}などの辞書でも見つけることができた。
        %この言葉の使い方は、\cite{鳥類学における統計学_2018}に乗っていた。
\end{SMbox}
    

\section{一般的な仮説検定の手順}
一般的な仮説検定の手順をまとめる。
%
\begin{framed}
    \begin{itemize}
        \item 帰無仮説($\mu = \mu_0$)・対立仮説($\mu\neq \mu_0$)を設定する。
        \item 仮説が正しいと考えたとき、検定統計量従う分布を考える(4)。
        \item $\alpha$を設定する。
        \item 母集団からの無作為抽出により標本を得る。
        \item 検定統計量を計算し、その出現する確率$p$値を計算する。それが$\alpha$以下であれば、$\mu=\mu_0$ではないと結論づける(帰無仮説が棄却された。)
    \end{itemize}
\end{framed}


\section{仮説検定の手順}
仮説検定の手順を確認します。
仮説検定では、仮説の前提が正しいことを決定する必要がある。
これは、特定の分布関数にデータが従っていることを前提にし、このことを検証できると決めているからである\footnote{検証できないと考えた方が良い}。%そのようなケースは実際の現象においては非常に稀であると考えられる。
ゆえに、データと想定した仮説の前提との違い・一致を注意深く検証しながら、仮説検定を利用することが求められている。
統計モデルがデータと乖離していれば、推定値が何を意味するかが捉えられなくなると考えられており、得られたデータを仮説の前提と一致するように調整することもある\footnote{禁じ手では？(感想)}。
%科学的仮説検定では、モデルを調整し、再度計測することを要求
%ので、統計モデルの改訂を要求されることもある。
%ただし、$p$値を小さくすることを目標に統計モデルを改訂してはいけない。

\begin{framed}
    \begin{enumerate}
        \item 過去の実験事実または予備実験から、無作為抽出したサンプルの出現頻度を予測する分布関数を特定する。ある点を中心に対称にデータが分布するのか、または、左右非対称にデータが分布するなどの知識・経験があったほうが良い。分布関数が全くわからないなら、正規分布を仮定する。
        \item 仮説検定を使う前提を確認する。
        \begin{quote}
            \begin{itemize}
                \item 確率変数は独立同一分布に従う
                \item 分布関数(正規分布など)
            \end{itemize}
        \end{quote}
        %\item 統計モデルに母数を設定する.経験的に知っている値や、過去の論文や予備実験で明らかになった値である方が良い
        %\item 統計モデルからサンプリングした確率変数の統計量が従う分布関数を探す。統計モデルの性質によって、母集団から得られた標本から得られた統計量の出現確率が計算可能になる。一般の仮説検定は本などでこの分布関数を確認する。
        \item 有意水準$\alpha$を設定する（さまざまな業界で$0.05$が設定される）。
        \item 母集団から無作為抽出を行い、標本を得る
        \item 標本が仮説の前提を満たしていることを確認する。標本分布と仮説の前提の分布関数がある程度一致していることを調べる。正規分布を前提にしているなら、正規分布の検定を行う。
        %\begin{quote}
            %標本が統計モデルにより推測できないと思われる場合、分布関数を変更し、統計モデルを再構築する。

            %または、母集団の性質が別の分布関数になったのだから、仮説検定を使うまでもなく、変化があったことが主張可能である。例えば、正規分布で推測できると(過去の実験や研究結果から)思われてたデータが、実際には指数分布的だった場合など。この場合、計測機器・無作為抽出の方法などに異常がなかったかも確認すべきである。
        %\end{quote}
        \item 標本から統計量を計算し、その値以上に大きな値をとる確率を計算する($p$値)。
        \item $p$値が$\alpha$以下であれば、帰無仮説を棄却し、対立仮説を採択する。
        \item $p$が$\alpha$以上であれば、判断を保留する（最終検定前の検定では採択する）。%\footnote{対立仮説を採択しない流派もあるが、採択していると考えるのが妥当である。}。
    \end{enumerate}
\end{framed}




\begin{SMbox}{第一の過誤・第二の過誤・統計モデルが正しい}
    Neyman-Pearson流の統計学の方言においては、$\alpha,\beta$を次のように定義する。帰無仮説が正しいとき、誤ってそのモデルを棄却してしまう間違いを第一の過誤といい、この確率を$\alpha$とする。また、対立仮説が正しいのに、帰無モデルを採択する間違いを第二の過誤といい、この確率を$\beta$とする。

    %私は、ある統計モデルが正しいとは考えないので、「モデルが正しいとき、間違えてそのモデルを棄却する間違い」ということを考える流派に同意できなかった。
    %仮説は棄却されることはあるが、正しいことや積極的に採択されることは稀であるというのはFisherの流派が近い。
    %ただし、Fisherは、「$p$値を帰無仮説が正しいという条件のもとで、手元にあるデータ、およびさらに極端なデータが得られる確率」と定義した[\cite{1573106361610039296}]。
    %ここでの正しいという言葉の意図が重要である。
    %私は、「統計モデルの仮説が自然を記述するのにほどほど良いと考えられるとき、手元にあるデータの統計量以上の隔たりが統計モデル内で得られる確率」という意味であると捉え直し、科学的仮説検定を提案した。

    %Neyman-Pearson流派の統計学の教科書を科学の分野で見つけることができていない。
    %Fisher流派とNeyman-Pearson流派の両方を書いている教科書は存在しているが、「帰無モデルが正しい」とはどういうことかを答えたものを見つけることができていない。

    %Fisher流派とNeyman-Pearson流派の両方を同じように扱うことが問題視されることもある[\cite{published_papers/18436201}]。
\end{SMbox}

\begin{SMbox}{正解と回答の違い}
回答がYesまたはNoである問題において、回答がYesな問題に、Yesと答えることを、True Positiveといい、Noと答えることをFalse Negativeという。回答がNoな問題に、Yesと答えることを、False Positive、また、Noと答えることをTrue negativeという。
\end{SMbox}


\begin{table}[hbtp]
\caption{正解と回答の違い}
%\label{table:data_type}
\centering
\begin{tabular}{ccc}
    \hline
    aa  & 陽性  &  陰性 \\
    \hline \hline
    陽性 & 真陽性 & 偽陽性  \\
    陰性 & 偽陰性 & 真陰性\\
\end{tabular}
\end{table}



\begin{SMbox}{過誤の概念}
第一の過誤・第二の過誤に関する批判として\cite{norleans2004臨床試験のための統計的方法}がある。
\cite{2010毒性試験に用いる統計解析法の動向}において引用されていた部分を引用しておく。私も彼らの意見に同意する。
\begin{quote}
過誤の概念は非現実的である。根本的な問題は、我々が真実を知らないことである。現実の臨床試験では、我々は実験から学び、真実を知りたいと願うのであって、真実がすでに知られており、我々の観察を判断するのに利用できる、というようなものではない。現在利用できる情報だけに基づく決定は、それ以上の情報が利用できるときには間違っていたことがわかることもあり得る。それ以上の情報が得られないとき、決定を行なった元になる情報でその決定の評価を行うことは理論的に不可能である。一つの試験では、試験さそのものから得られる情報が、利用できる唯一の情報である。利用できる情報の調査と競合する利害の注意深いバランスを考慮した後でのみ、仮説の棄却や採択の判断が行われる。その後の試験の情報が利用できるようになるまでは、現在の判断が正しいか誤りかを判断する情報は存在しない。従って、一つの試験にとっては、過誤の考え方は全く意味を持たない。
\end{quote}
\end{SMbox}
